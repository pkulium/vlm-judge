{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"./batch.json\"\n",
    "with open(input_file, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating_str:\n",
      "rating:None\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from statistics import mean\n",
    "\n",
    "# Load the JSON data from the file\n",
    "file_path = 'batch.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Define the list of candidate models and judge models\n",
    "candidate_model = [\"llama_vid\", \"gpt4v\", \"video_chatgpt\", \"mplug_owl_Video\", \"video_llava\"]\n",
    "# judge_model = ['video_llava', 'llama_vid', 'gpt4v', 'internvl2']  # Assuming 'mplug_owl_Video' is not a judge\n",
    "judge_model = ['gpt4v', 'internvl2']  # Assuming 'mplug_owl_Video' is not a judge\n",
    "\n",
    "# Initialize the data structure for storing scores\n",
    "dataset2data = {}\n",
    "\n",
    "# Function to extract ratings from JSON-formatted strings\n",
    "import re\n",
    "import json\n",
    "\n",
    "def extract_rating(rating_string):\n",
    "    \"\"\"\n",
    "    Extracts the rating number from a string using regex to handle different formats.\n",
    "    \n",
    "    Args:\n",
    "    rating_string (str): The input string containing the rating.\n",
    "    \n",
    "    Returns:\n",
    "    int: The extracted rating number or None if not found.\n",
    "    \"\"\"\n",
    "    # Regex pattern to find rating in different formats\n",
    "    # patterns = [\n",
    "    #     r\"rating['\\\"]?\\s*:\\s*['\\\"]?(\\d+)\",  # Matches JSON-like formats with 'rating' key\n",
    "    #     r\"^(\\d+)\\s*\\(\",                     # Matches formats like \"4 (Excellent)\"\n",
    "    #     r\"^(\\d+)$\",                         # Matches plain number formats like \"4\"\n",
    "    # ]\n",
    "    patterns = [\n",
    "        r\"rating['\\\"]?\\s*:\\s*['\\\"]?(\\d+)\",   # Matches JSON-like formats with 'rating' key\n",
    "        r\"rating['\\\"]?\\s*:\\s*['\\\"]?\\[\\[(\\d+)\\]\\]\",  # Matches JSON-like formats with rating enclosed in double brackets\n",
    "        r\"rating['\\\"]?\\s*:\\s*['\\\"]?\\[(\\d+)\\]\",  # Matches JSON-like formats with rating enclosed in single brackets\n",
    "        r\"^(\\d+)\\s*\\(\",                      # Matches formats like \"4 (Excellent)\"\n",
    "        r\"^(\\d+)$\",                          # Matches plain number formats like \"4\"\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, rating_string)\n",
    "        if match:\n",
    "            return int(match.group(1))\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Iterate through each dataset and each sample, collecting ratings\n",
    "for dataset, samples in data.items():\n",
    "    results = {judge: {candidate: [] for candidate in candidate_model} for judge in judge_model}\n",
    "    for sample_id, sample_data in samples.items():\n",
    "        for judge in judge_model:\n",
    "            if judge in sample_data:\n",
    "                rating_info = sample_data[judge]\n",
    "                for candidate, rating_str in rating_info.items():\n",
    "                    rating = extract_rating(rating_str)\n",
    "                    if rating is not None:\n",
    "                        results[judge][candidate].append(rating)\n",
    "                    else:\n",
    "                        print(f'rating_str:{rating_str}')\n",
    "                        print(f'rating:{rating}')\n",
    "                        results[judge][candidate].append(0)\n",
    "    dataset2data[dataset] = results\n",
    "\n",
    "    # # Calculate average ratings for each candidate model under each judge for the dataset\n",
    "    # for judge, candidates in results.items():\n",
    "    #     for candidate, ratings in candidates.items():\n",
    "    #         if ratings:\n",
    "    #             average = round(mean(ratings), 2)\n",
    "    #         else:\n",
    "    #             average = None\n",
    "    #         if dataset not in dataset2data:\n",
    "    #             dataset2data[dataset] = {}\n",
    "    #         if judge not in dataset2data[dataset]:\n",
    "    #             dataset2data[dataset][judge] = {}\n",
    "    #             dataset2data[dataset][judge][candidate] = results[judge][candidate]\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# gpt_debate score\n",
    "input_file = \"../logs_phase1_processed/batch_with_score.json\"\n",
    "with open(input_file, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, samples in data.items():\n",
    "    results = {'gpt_debate': {candidate: [] for candidate in candidate_model}}\n",
    "    for sample_id, sample_data in samples.items():\n",
    "        for candidate in candidate_model:\n",
    "            rating = sample_data[candidate][1]\n",
    "            results['gpt_debate'][candidate].append(rating)\n",
    "    dataset2data[dataset]['gpt_debate'] = results['gpt_debate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get statistics of judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_match = 0\n",
    "judge_model_all = judge_model + ['gpt_debate']\n",
    "judge2statistics = {judge: {i:0 for i in range(6)} for judge in judge_model_all}\n",
    "for dataset, data in dataset2data.items():\n",
    "    for judge in judge_model_all:\n",
    "        for candidate in candidate_model:\n",
    "            for rating in dataset2data[dataset][judge][candidate]:\n",
    "                if rating:\n",
    "                    judge2statistics[judge][rating] += 1\n",
    "                else:\n",
    "                    missing_match += 1\n",
    "missing_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'video_llava'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2data[dataset][judge][candidate]\n",
    "candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvrr_continuity_and_object_instance_count': {'llama_vid': {'gpt4v': 2.7344632768361583,\n",
       "   'internvl2': 3.2542372881355934,\n",
       "   'gpt_debate': 1.9435028248587571},\n",
       "  'gpt4v': {'gpt4v': 3.056497175141243,\n",
       "   'internvl2': 3.310734463276836,\n",
       "   'gpt_debate': 2.4745762711864407},\n",
       "  'video_chatgpt': {'gpt4v': 2.531073446327684,\n",
       "   'internvl2': 2.977401129943503,\n",
       "   'gpt_debate': 2.135593220338983},\n",
       "  'mplug_owl_Video': {'gpt4v': 2.6045197740112993,\n",
       "   'internvl2': 3.310734463276836,\n",
       "   'gpt_debate': 1.8531073446327684},\n",
       "  'video_llava': {'gpt4v': 2.672316384180791,\n",
       "   'internvl2': 3.310734463276836,\n",
       "   'gpt_debate': 1.9661016949152543}},\n",
       " 'cvrr_fine_grained_action_understanding': {'llama_vid': {'gpt4v': 3.0478260869565217,\n",
       "   'internvl2': 3.5434782608695654,\n",
       "   'gpt_debate': 1.934782608695652},\n",
       "  'gpt4v': {'gpt4v': 3.4391304347826086,\n",
       "   'internvl2': 3.5521739130434784,\n",
       "   'gpt_debate': 3.082608695652174},\n",
       "  'video_chatgpt': {'gpt4v': 2.9608695652173913,\n",
       "   'internvl2': 3.391304347826087,\n",
       "   'gpt_debate': 1.9652173913043478},\n",
       "  'mplug_owl_Video': {'gpt4v': 3.082608695652174,\n",
       "   'internvl2': 3.5043478260869567,\n",
       "   'gpt_debate': 2.0695652173913044},\n",
       "  'video_llava': {'gpt4v': 2.991304347826087,\n",
       "   'internvl2': 3.4347826086956523,\n",
       "   'gpt_debate': 2.0652173913043477}},\n",
       " 'cvrr_interpretation_of_social_context': {'llama_vid': {'gpt4v': 2.307142857142857,\n",
       "   'internvl2': 3.0428571428571427,\n",
       "   'gpt_debate': 1.5321428571428573},\n",
       "  'gpt4v': {'gpt4v': 3.317857142857143,\n",
       "   'internvl2': 3.525,\n",
       "   'gpt_debate': 3.092857142857143},\n",
       "  'video_chatgpt': {'gpt4v': 2.5714285714285716,\n",
       "   'internvl2': 3.017857142857143,\n",
       "   'gpt_debate': 2.1714285714285713},\n",
       "  'mplug_owl_Video': {'gpt4v': 2.5785714285714287,\n",
       "   'internvl2': 3.2071428571428573,\n",
       "   'gpt_debate': 1.9964285714285714},\n",
       "  'video_llava': {'gpt4v': 2.225,\n",
       "   'internvl2': 3.0285714285714285,\n",
       "   'gpt_debate': 1.8928571428571428}},\n",
       " 'cvrr_interpretation_of_visual_context': {'llama_vid': {'gpt4v': 2.8315018315018317,\n",
       "   'internvl2': 3.2014652014652016,\n",
       "   'gpt_debate': 1.7545787545787546},\n",
       "  'gpt4v': {'gpt4v': 3.468864468864469,\n",
       "   'internvl2': 3.3956043956043955,\n",
       "   'gpt_debate': 2.9816849816849818},\n",
       "  'video_chatgpt': {'gpt4v': 2.8315018315018317,\n",
       "   'internvl2': 3.043956043956044,\n",
       "   'gpt_debate': 2.172161172161172},\n",
       "  'mplug_owl_Video': {'gpt4v': 2.93040293040293,\n",
       "   'internvl2': 3.326007326007326,\n",
       "   'gpt_debate': 2.0732600732600734},\n",
       "  'video_llava': {'gpt4v': 2.619047619047619,\n",
       "   'internvl2': 3.0586080586080584,\n",
       "   'gpt_debate': 1.9377289377289377}},\n",
       " 'cvrr_multiple_actions_in_a_single_video': {'llama_vid': {'gpt4v': 2.69811320754717,\n",
       "   'internvl2': 3.1132075471698113,\n",
       "   'gpt_debate': 1.7358490566037736},\n",
       "  'gpt4v': {'gpt4v': 3.069182389937107,\n",
       "   'internvl2': 3.2169811320754715,\n",
       "   'gpt_debate': 2.3364779874213837},\n",
       "  'video_chatgpt': {'gpt4v': 2.610062893081761,\n",
       "   'internvl2': 3.0628930817610063,\n",
       "   'gpt_debate': 2.0660377358490565},\n",
       "  'mplug_owl_Video': {'gpt4v': 2.5157232704402515,\n",
       "   'internvl2': 3.110062893081761,\n",
       "   'gpt_debate': 1.6540880503144655},\n",
       "  'video_llava': {'gpt4v': 2.5440251572327046,\n",
       "   'internvl2': 3.1226415094339623,\n",
       "   'gpt_debate': 1.7044025157232705}},\n",
       " 'cvrr_non_existent_actions_with_existent_scene_depictions': {'llama_vid': {'gpt4v': 2.4347826086956523,\n",
       "   'internvl2': 3.420289855072464,\n",
       "   'gpt_debate': 1.108695652173913},\n",
       "  'gpt4v': {'gpt4v': 3.0434782608695654,\n",
       "   'internvl2': 3.1956521739130435,\n",
       "   'gpt_debate': 2.8550724637681157},\n",
       "  'video_chatgpt': {'gpt4v': 2.5217391304347827,\n",
       "   'internvl2': 3.289855072463768,\n",
       "   'gpt_debate': 1.7608695652173914},\n",
       "  'mplug_owl_Video': {'gpt4v': 2.4565217391304346,\n",
       "   'internvl2': 3.5,\n",
       "   'gpt_debate': 1.2971014492753623},\n",
       "  'video_llava': {'gpt4v': 2.282608695652174,\n",
       "   'internvl2': 3.369565217391304,\n",
       "   'gpt_debate': 1.2246376811594204}},\n",
       " 'cvrr_non_existent_actions_with_non_existent_scene_depictions': {'llama_vid': {'gpt4v': 2.4791666666666665,\n",
       "   'internvl2': 2.9791666666666665,\n",
       "   'gpt_debate': 1.1736111111111112},\n",
       "  'gpt4v': {'gpt4v': 2.861111111111111,\n",
       "   'internvl2': 3.0069444444444446,\n",
       "   'gpt_debate': 2.7916666666666665},\n",
       "  'video_chatgpt': {'gpt4v': 2.611111111111111,\n",
       "   'internvl2': 3.048611111111111,\n",
       "   'gpt_debate': 1.5555555555555556},\n",
       "  'mplug_owl_Video': {'gpt4v': 2.5555555555555554,\n",
       "   'internvl2': 3.0902777777777777,\n",
       "   'gpt_debate': 1.1944444444444444},\n",
       "  'video_llava': {'gpt4v': 2.361111111111111,\n",
       "   'internvl2': 2.9791666666666665,\n",
       "   'gpt_debate': 1.3125}},\n",
       " 'cvrr_partial_actions': {'llama_vid': {'gpt4v': 2.8446601941747574,\n",
       "   'internvl2': 3.466019417475728,\n",
       "   'gpt_debate': 1.4611650485436893},\n",
       "  'gpt4v': {'gpt4v': 3.3737864077669903,\n",
       "   'internvl2': 3.4611650485436893,\n",
       "   'gpt_debate': 2.8058252427184467},\n",
       "  'video_chatgpt': {'gpt4v': 2.703883495145631,\n",
       "   'internvl2': 3.2427184466019416,\n",
       "   'gpt_debate': 1.8203883495145632},\n",
       "  'mplug_owl_Video': {'gpt4v': 2.8883495145631066,\n",
       "   'internvl2': 3.4029126213592233,\n",
       "   'gpt_debate': 1.7281553398058251},\n",
       "  'video_llava': {'gpt4v': 2.6553398058252426,\n",
       "   'internvl2': 3.3689320388349513,\n",
       "   'gpt_debate': 1.6310679611650485}},\n",
       " 'cvrr_time_order_understanding': {'llama_vid': {'gpt4v': 3.085526315789474,\n",
       "   'internvl2': 3.611842105263158,\n",
       "   'gpt_debate': 1.894736842105263},\n",
       "  'gpt4v': {'gpt4v': 3.4802631578947367,\n",
       "   'internvl2': 3.7434210526315788,\n",
       "   'gpt_debate': 2.401315789473684},\n",
       "  'video_chatgpt': {'gpt4v': 2.9473684210526314,\n",
       "   'internvl2': 3.4078947368421053,\n",
       "   'gpt_debate': 1.9342105263157894},\n",
       "  'mplug_owl_Video': {'gpt4v': 3.085526315789474,\n",
       "   'internvl2': 3.638157894736842,\n",
       "   'gpt_debate': 1.9407894736842106},\n",
       "  'video_llava': {'gpt4v': 2.9276315789473686,\n",
       "   'internvl2': 3.5065789473684212,\n",
       "   'gpt_debate': 1.9539473684210527}},\n",
       " 'cvrr_understanding_emotional_context': {'llama_vid': {'gpt4v': 2.8801369863013697,\n",
       "   'internvl2': 3.2260273972602738,\n",
       "   'gpt_debate': 1.5856164383561644},\n",
       "  'gpt4v': {'gpt4v': 3.2226027397260273,\n",
       "   'internvl2': 3.3184931506849313,\n",
       "   'gpt_debate': 2.2945205479452055},\n",
       "  'video_chatgpt': {'gpt4v': 2.835616438356164,\n",
       "   'internvl2': 3.1404109589041096,\n",
       "   'gpt_debate': 1.6917808219178083},\n",
       "  'mplug_owl_Video': {'gpt4v': 2.9280821917808217,\n",
       "   'internvl2': 3.2773972602739727,\n",
       "   'gpt_debate': 1.61986301369863},\n",
       "  'video_llava': {'gpt4v': 2.660958904109589,\n",
       "   'internvl2': 3.1678082191780823,\n",
       "   'gpt_debate': 1.5684931506849316}},\n",
       " 'cvrr_unusual_and_physically_anomalous_activities': {'llama_vid': {'gpt4v': 2.405263157894737,\n",
       "   'internvl2': 3.3473684210526318,\n",
       "   'gpt_debate': 1.5368421052631578},\n",
       "  'gpt4v': {'gpt4v': 3.1789473684210527,\n",
       "   'internvl2': 3.568421052631579,\n",
       "   'gpt_debate': 2.663157894736842},\n",
       "  'video_chatgpt': {'gpt4v': 2.4105263157894736,\n",
       "   'internvl2': 3.1842105263157894,\n",
       "   'gpt_debate': 1.5368421052631578},\n",
       "  'mplug_owl_Video': {'gpt4v': 2.4947368421052634,\n",
       "   'internvl2': 3.4947368421052634,\n",
       "   'gpt_debate': 1.568421052631579},\n",
       "  'video_llava': {'gpt4v': 2.3,\n",
       "   'internvl2': 3.2578947368421054,\n",
       "   'gpt_debate': 1.5315789473684212}}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge_model_all = judge_model + ['gpt_debate']\n",
    "candidate2statistics = {dataset: {candidate: {judge:[] for judge in judge_model_all} for candidate in candidate_model} for dataset in dataset2data}\n",
    "for dataset, data in dataset2data.items():\n",
    "    for judge in judge_model_all:\n",
    "        for candidate in candidate_model:\n",
    "            for rating in dataset2data[dataset][judge][candidate]:\n",
    "                candidate2statistics[dataset][candidate][judge].append(rating)\n",
    "            candidate2statistics[dataset][candidate][judge] = sum(candidate2statistics[dataset][candidate][judge]) / len(candidate2statistics[dataset][candidate][judge])\n",
    "candidate2statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "def get_agreement_with_baseline(dataset2data, dataset, judge, candidate):\n",
    "    ratings1 = dataset2data[dataset][judge][candidate]\n",
    "    ratings2 = dataset2data[dataset]['gpt_debate'][candidate]\n",
    "    # print(f\"ratings1:{ratings1}\")\n",
    "    # print(f\"ratings2:{ratings2}\")\n",
    "    # Calculate Weighted Kappa with linear weights\n",
    "    # kappa = cohen_kappa_score(ratings1, ratings2)\n",
    "    # print(\"Kappa:\", kappa)\n",
    "\n",
    "    # # Calculate Weighted Kappa with linear weights\n",
    "    # weighted_kappa_linear = cohen_kappa_score(ratings1, ratings2, weights='linear')\n",
    "    # print(\"Weighted Kappa (Linear):\", weighted_kappa_linear)\n",
    "\n",
    "    # Calculate Weighted Kappa with quadratic weights\n",
    "    weighted_kappa_quadratic = cohen_kappa_score(ratings1, ratings2, weights='quadratic')\n",
    "    # print(\"Weighted Kappa (Quadratic):\", weighted_kappa_quadratic)\n",
    "    return weighted_kappa_quadratic\n",
    "\n",
    "dataset2agreement = {}\n",
    "for dataset, data in dataset2data.items():\n",
    "    dataset2agreement[dataset] = {}\n",
    "    for judge in judge_model:\n",
    "        dataset2agreement[dataset][judge] = {}\n",
    "        judge_total = 0\n",
    "        for candidate in candidate_model:\n",
    "            dataset2agreement[dataset][judge][candidate] = get_agreement_with_baseline(dataset2data, dataset, judge, candidate)\n",
    "            judge_total += dataset2agreement[dataset][judge][candidate]\n",
    "        dataset2agreement[dataset][judge]['average'] = judge_total / len(dataset2agreement[dataset][judge])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvrr_continuity_and_object_instance_count': {'gpt4v': {'llama_vid': 0.1475962134678186,\n",
       "   'gpt4v': 0.40171728079648117,\n",
       "   'video_chatgpt': 0.28344166951761884,\n",
       "   'mplug_owl_Video': 0.10580744178398194,\n",
       "   'video_llava': 0.14180061676172817,\n",
       "   'average': 0.21607264446552574},\n",
       "  'internvl2': {'llama_vid': 0.02868342172008309,\n",
       "   'gpt4v': 0.24977019711980386,\n",
       "   'video_chatgpt': 0.08700480409434375,\n",
       "   'mplug_owl_Video': 0.0046608237499367045,\n",
       "   'video_llava': 0.04035856250506997,\n",
       "   'average': 0.08209556183784747}},\n",
       " 'cvrr_fine_grained_action_understanding': {'gpt4v': {'llama_vid': 0.2837257585051668,\n",
       "   'gpt4v': 0.2641869533577734,\n",
       "   'video_chatgpt': 0.3451393537246684,\n",
       "   'mplug_owl_Video': 0.3768800827473643,\n",
       "   'video_llava': 0.40361982463543855,\n",
       "   'average': 0.3347103945940823},\n",
       "  'internvl2': {'llama_vid': 0.14817963407872858,\n",
       "   'gpt4v': 0.19636830472358613,\n",
       "   'video_chatgpt': 0.13495183044315995,\n",
       "   'mplug_owl_Video': 0.16215470036964896,\n",
       "   'video_llava': 0.17253453384124062,\n",
       "   'average': 0.16283780069127285}},\n",
       " 'cvrr_interpretation_of_social_context': {'gpt4v': {'llama_vid': 0.3742087528971817,\n",
       "   'gpt4v': 0.34666844807512454,\n",
       "   'video_chatgpt': 0.5518994914747233,\n",
       "   'mplug_owl_Video': 0.5054018325203994,\n",
       "   'video_llava': 0.34817563388991957,\n",
       "   'average': 0.4252708317714696},\n",
       "  'internvl2': {'llama_vid': 0.08391007478285095,\n",
       "   'gpt4v': 0.23949396539188605,\n",
       "   'video_chatgpt': 0.11041472196292856,\n",
       "   'mplug_owl_Video': 0.08993943990803388,\n",
       "   'video_llava': -0.010467380720545316,\n",
       "   'average': 0.10265816426503083}},\n",
       " 'cvrr_interpretation_of_visual_context': {'gpt4v': {'llama_vid': 0.2858651633525211,\n",
       "   'gpt4v': 0.33349421980215654,\n",
       "   'video_chatgpt': 0.37172087954631816,\n",
       "   'mplug_owl_Video': 0.4201687811508835,\n",
       "   'video_llava': 0.28708181190170723,\n",
       "   'average': 0.3396661711507173},\n",
       "  'internvl2': {'llama_vid': 0.12417499329752657,\n",
       "   'gpt4v': 0.24516835324004538,\n",
       "   'video_chatgpt': 0.1406358122684902,\n",
       "   'mplug_owl_Video': 0.09087962089777457,\n",
       "   'video_llava': -6.146017073493937e-06,\n",
       "   'average': 0.12017052673735265}},\n",
       " 'cvrr_multiple_actions_in_a_single_video': {'gpt4v': {'llama_vid': 0.23231885988279166,\n",
       "   'gpt4v': 0.3518666333575028,\n",
       "   'video_chatgpt': 0.3614457831325302,\n",
       "   'mplug_owl_Video': 0.29432755643665665,\n",
       "   'video_llava': 0.32616152543088117,\n",
       "   'average': 0.3132240716480725},\n",
       "  'internvl2': {'llama_vid': 0.10666918775829937,\n",
       "   'gpt4v': 0.20758031659409049,\n",
       "   'video_chatgpt': 0.08812917067190484,\n",
       "   'mplug_owl_Video': 0.1177776133757491,\n",
       "   'video_llava': 0.10569794259058984,\n",
       "   'average': 0.12517084619812674}},\n",
       " 'cvrr_non_existent_actions_with_existent_scene_depictions': {'gpt4v': {'llama_vid': 0.07621009268795054,\n",
       "   'gpt4v': 0.09663746821135921,\n",
       "   'video_chatgpt': 0.2021183558449131,\n",
       "   'mplug_owl_Video': 0.19549703487787717,\n",
       "   'video_llava': 0.10232955238443708,\n",
       "   'average': 0.13455850080130743},\n",
       "  'internvl2': {'llama_vid': 0.012567755552357673,\n",
       "   'gpt4v': -0.09062170706006323,\n",
       "   'video_chatgpt': -0.13114754098360648,\n",
       "   'mplug_owl_Video': -0.005428881650380024,\n",
       "   'video_llava': -0.0033595747881460802,\n",
       "   'average': -0.04359798978596763}},\n",
       " 'cvrr_non_existent_actions_with_non_existent_scene_depictions': {'gpt4v': {'llama_vid': 0.027241021773965368,\n",
       "   'gpt4v': -0.13226621735467559,\n",
       "   'video_chatgpt': 0.1334527541424093,\n",
       "   'mplug_owl_Video': 0.04779582366589319,\n",
       "   'video_llava': 0.05987261146496814,\n",
       "   'average': 0.027219198738512085},\n",
       "  'internvl2': {'llama_vid': -0.03293681630701162,\n",
       "   'gpt4v': -0.1676436107854633,\n",
       "   'video_chatgpt': -0.04358432265408996,\n",
       "   'mplug_owl_Video': -0.047121200806512054,\n",
       "   'video_llava': -0.030042918454935563,\n",
       "   'average': -0.0642657738016025}},\n",
       " 'cvrr_partial_actions': {'gpt4v': {'llama_vid': 0.14106579222087123,\n",
       "   'gpt4v': 0.3360815469944536,\n",
       "   'video_chatgpt': 0.17030917188407668,\n",
       "   'mplug_owl_Video': 0.25480022631788035,\n",
       "   'video_llava': 0.19267099886112415,\n",
       "   'average': 0.2189855472556812},\n",
       "  'internvl2': {'llama_vid': 0.01941014372825811,\n",
       "   'gpt4v': 0.21047205733193652,\n",
       "   'video_chatgpt': -0.028180833520359938,\n",
       "   'mplug_owl_Video': -0.021255672539944426,\n",
       "   'video_llava': -0.04763129909780095,\n",
       "   'average': 0.026562879180417866}},\n",
       " 'cvrr_time_order_understanding': {'gpt4v': {'llama_vid': 0.12752558383626345,\n",
       "   'gpt4v': 0.26456555339022914,\n",
       "   'video_chatgpt': 0.26187998612556374,\n",
       "   'mplug_owl_Video': 0.2250657353324903,\n",
       "   'video_llava': 0.20280336961314427,\n",
       "   'average': 0.21636804565953818},\n",
       "  'internvl2': {'llama_vid': -0.002972152225883651,\n",
       "   'gpt4v': 0.05701796247160562,\n",
       "   'video_chatgpt': -0.014987011256910598,\n",
       "   'mplug_owl_Video': 0.06628157574513627,\n",
       "   'video_llava': 0.04347967850796397,\n",
       "   'average': 0.02976401064838232}},\n",
       " 'cvrr_understanding_emotional_context': {'gpt4v': {'llama_vid': 0.16202709535911541,\n",
       "   'gpt4v': 0.1380997518748781,\n",
       "   'video_chatgpt': 0.15434752841298105,\n",
       "   'mplug_owl_Video': 0.18980633791814838,\n",
       "   'video_llava': 0.17143768802990245,\n",
       "   'average': 0.16314368031900509},\n",
       "  'internvl2': {'llama_vid': 0.07909551898996181,\n",
       "   'gpt4v': 0.03792153434528067,\n",
       "   'video_chatgpt': 0.028812155932506744,\n",
       "   'mplug_owl_Video': 0.0652179333110604,\n",
       "   'video_llava': 0.08905849701110169,\n",
       "   'average': 0.06002112791798227}},\n",
       " 'cvrr_unusual_and_physically_anomalous_activities': {'gpt4v': {'llama_vid': 0.16522301767861247,\n",
       "   'gpt4v': 0.07285596825510321,\n",
       "   'video_chatgpt': 0.1896512851345259,\n",
       "   'mplug_owl_Video': 0.2585898172235548,\n",
       "   'video_llava': 0.18977313647821392,\n",
       "   'average': 0.17521864495400205},\n",
       "  'internvl2': {'llama_vid': 0.02007774881830615,\n",
       "   'gpt4v': -0.02747523813138031,\n",
       "   'video_chatgpt': 0.04339718596372244,\n",
       "   'mplug_owl_Video': 0.04951543924353574,\n",
       "   'video_llava': 0.03605289025588987,\n",
       "   'average': 0.02431360523001478}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2average = {}\n",
    "judge_model.append('gpt_debate')\n",
    "for dataset, data in dataset2data.items():\n",
    "    dataset2average[dataset] = {}\n",
    "    for judge in judge_model:\n",
    "        dataset2average[dataset][judge] = {}\n",
    "        judge_total = 0\n",
    "        for candidate in candidate_model:\n",
    "            judge_total += sum(dataset2data[dataset][judge][candidate]) / len(dataset2data[dataset][judge][candidate])\n",
    "        dataset2average[dataset][judge] = judge_total / len(candidate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvrr_continuity_and_object_instance_count': {'gpt4v': 2.719774011299435,\n",
       "  'internvl2': 3.232768361581921,\n",
       "  'gpt_debate': 2.074576271186441},\n",
       " 'cvrr_fine_grained_action_understanding': {'gpt4v': 3.104347826086957,\n",
       "  'internvl2': 3.485217391304348,\n",
       "  'gpt_debate': 2.223478260869565},\n",
       " 'cvrr_interpretation_of_social_context': {'gpt4v': 2.6,\n",
       "  'internvl2': 3.164285714285714,\n",
       "  'gpt_debate': 2.137142857142857},\n",
       " 'cvrr_interpretation_of_visual_context': {'gpt4v': 2.9362637362637365,\n",
       "  'internvl2': 3.2051282051282053,\n",
       "  'gpt_debate': 2.183882783882784},\n",
       " 'cvrr_multiple_actions_in_a_single_video': {'gpt4v': 2.687421383647799,\n",
       "  'internvl2': 3.125157232704402,\n",
       "  'gpt_debate': 1.89937106918239},\n",
       " 'cvrr_non_existent_actions_with_existent_scene_depictions': {'gpt4v': 2.5478260869565217,\n",
       "  'internvl2': 3.3550724637681157,\n",
       "  'gpt_debate': 1.6492753623188405},\n",
       " 'cvrr_non_existent_actions_with_non_existent_scene_depictions': {'gpt4v': 2.573611111111111,\n",
       "  'internvl2': 3.020833333333333,\n",
       "  'gpt_debate': 1.6055555555555556},\n",
       " 'cvrr_partial_actions': {'gpt4v': 2.8932038834951457,\n",
       "  'internvl2': 3.3883495145631066,\n",
       "  'gpt_debate': 1.8893203883495147},\n",
       " 'cvrr_time_order_understanding': {'gpt4v': 3.105263157894737,\n",
       "  'internvl2': 3.5815789473684214,\n",
       "  'gpt_debate': 2.025},\n",
       " 'cvrr_understanding_emotional_context': {'gpt4v': 2.905479452054794,\n",
       "  'internvl2': 3.2260273972602738,\n",
       "  'gpt_debate': 1.7520547945205478},\n",
       " 'cvrr_unusual_and_physically_anomalous_activities': {'gpt4v': 2.5578947368421057,\n",
       "  'internvl2': 3.3705263157894736,\n",
       "  'gpt_debate': 1.7673684210526315}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvrr_continuity_and_object_instance_count-gpt4v\n",
      "0.21607264446552574\n",
      "cvrr_continuity_and_object_instance_count-internvl2\n",
      "0.08209556183784747\n",
      "cvrr_fine_grained_action_understanding-gpt4v\n",
      "0.3347103945940823\n",
      "cvrr_fine_grained_action_understanding-internvl2\n",
      "0.16283780069127285\n",
      "cvrr_interpretation_of_social_context-gpt4v\n",
      "0.4252708317714696\n",
      "cvrr_interpretation_of_social_context-internvl2\n",
      "0.10265816426503083\n",
      "cvrr_interpretation_of_visual_context-gpt4v\n",
      "0.3396661711507173\n",
      "cvrr_interpretation_of_visual_context-internvl2\n",
      "0.12017052673735265\n",
      "cvrr_multiple_actions_in_a_single_video-gpt4v\n",
      "0.3132240716480725\n",
      "cvrr_multiple_actions_in_a_single_video-internvl2\n",
      "0.12517084619812674\n",
      "cvrr_non_existent_actions_with_existent_scene_depictions-gpt4v\n",
      "0.13455850080130743\n",
      "cvrr_non_existent_actions_with_existent_scene_depictions-internvl2\n",
      "-0.04359798978596763\n",
      "cvrr_non_existent_actions_with_non_existent_scene_depictions-gpt4v\n",
      "0.027219198738512085\n",
      "cvrr_non_existent_actions_with_non_existent_scene_depictions-internvl2\n",
      "-0.0642657738016025\n",
      "cvrr_partial_actions-gpt4v\n",
      "0.2189855472556812\n",
      "cvrr_partial_actions-internvl2\n",
      "0.026562879180417866\n",
      "cvrr_time_order_understanding-gpt4v\n",
      "0.21636804565953818\n",
      "cvrr_time_order_understanding-internvl2\n",
      "0.02976401064838232\n",
      "cvrr_understanding_emotional_context-gpt4v\n",
      "0.16314368031900509\n",
      "cvrr_understanding_emotional_context-internvl2\n",
      "0.06002112791798227\n",
      "cvrr_unusual_and_physically_anomalous_activities-gpt4v\n",
      "0.17521864495400205\n",
      "cvrr_unusual_and_physically_anomalous_activities-internvl2\n",
      "0.02431360523001478\n"
     ]
    }
   ],
   "source": [
    "for dataset, data in dataset2agreement.items():\n",
    "    for judge in judge_model:\n",
    "        if judge == 'gpt_debate':\n",
    "            continue\n",
    "        print(f'{dataset}-{judge}')\n",
    "        print(dataset2agreement[dataset][judge]['average'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt4v': {'llama_vid': 0.16522301767861247,\n",
       "  'gpt4v': 0.07285596825510321,\n",
       "  'video_chatgpt': 0.1896512851345259,\n",
       "  'mplug_owl_Video': 0.2585898172235548,\n",
       "  'video_llava': 0.18977313647821392,\n",
       "  'average': 0.17521864495400205},\n",
       " 'internvl2': {'llama_vid': 0.02007774881830615,\n",
       "  'gpt4v': -0.02747523813138031,\n",
       "  'video_chatgpt': 0.04339718596372244,\n",
       "  'mplug_owl_Video': 0.04951543924353574,\n",
       "  'video_llava': 0.03605289025588987,\n",
       "  'average': 0.02431360523001478}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2agreement[dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
