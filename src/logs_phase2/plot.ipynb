{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Data for the models\n",
    "# data = {\n",
    "#     \"Model\": [\"video_llava\", \"llama_vid\", \"gpt4v\"],\n",
    "#     \"Continuity\": [0.0085, 0.0289, 0.1173],\n",
    "#     \"Fine Action\": [-0.0098, -0.0047, 0.2313],\n",
    "#     \"Social Context\": [0.0208, -0.0104, 0.1754],\n",
    "#     \"Visual Context\": [0.0290, 0.0168, 0.1719],\n",
    "#     \"Multiple Actions\": [-0.0053, -0.0107, 0.1522],\n",
    "#     \"Existent Actions\": [-0.0367, -0.0547, -0.0152],\n",
    "#     \"Non-existent Actions\": [-0.0353, -0.0676, -0.0877],\n",
    "#     \"Partial Actions\": [0.0024, -0.0105, 0.0009],\n",
    "#     \"Time Order\": [0.0029, 0.0220, 0.0901],\n",
    "#     \"Emotional Context\": [-0.0016, -0.0154, 0.1184],\n",
    "#     \"Anomalous Activities\": [-0.0041, -0.0205, 0.0671],\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "# df.set_index(\"Model\", inplace=True)\n",
    "\n",
    "# # Plotting with improvements\n",
    "# fig, ax = plt.subplots(figsize=(14, 8))\n",
    "# df.T.plot(kind='bar', ax=ax, colormap='viridis')  # Using a colormap for better color distinction\n",
    "# plt.title('Average Performance of Video Language Models on Various CVRR Dimensions', fontsize=16)\n",
    "# plt.xlabel('Dimension', fontsize=14)\n",
    "# plt.ylabel('Performance', fontsize=14)\n",
    "# plt.xticks(rotation=45, fontsize=12)\n",
    "# plt.yticks(fontsize=12)\n",
    "# plt.axhline(y=0.1, color='red', linestyle='--', label='Baseline (y=0.1)')\n",
    "# plt.legend(title='Model', fontsize=12, title_fontsize=14, loc='upper left', bbox_to_anchor=(1, 1))\n",
    "# plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Save the figure\n",
    "# file_path = 'ICLR_Conference_Video_Language_Models_Performance_Plot.png'\n",
    "# plt.savefig(file_path)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: llama_vid, Lengths: [80, 103, 54, 65, 56, 82, 215, 77, 90, 98]\n",
      "Model: gpt4v, Lengths: [114, 274, 71, 303, 128, 526, 62, 232, 377, 115]\n",
      "Model: video_chatgpt, Lengths: [67, 86, 251, 73, 54, 90, 55, 77, 57, 98]\n",
      "Model: mplug_owl_Video, Lengths: [67, 101, 76, 80, 96, 123, 55, 77, 68, 98]\n",
      "Model: video_llava, Lengths: [73, 92, 92, 120, 55, 139, 55, 77, 76, 98]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "# Load the JSON data from the file\n",
    "file_path = '../logs_phase1_processed/batch.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Collect the length of responses for each model across all datasets\n",
    "length_distribution = defaultdict(list)\n",
    "\n",
    "for dataset_name, dataset_records in data.items():\n",
    "    for record_id, responses in dataset_records.items():\n",
    "        for model, response in responses.items():\n",
    "            if model != 'target':  # Exclude 'target'\n",
    "                length_distribution[model].append(len(response[0]))\n",
    "\n",
    "# Display the length distribution\n",
    "for model, lengths in length_distribution.items():\n",
    "    lengths = lengths[:10]\n",
    "    print(f\"Model: {model}, Lengths: {lengths}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Plotting the KDE (Kernel Density Estimate) distribution for each model\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for model, lengths in length_distribution.items():\n",
    "    sns.kdeplot(lengths, label=model, shade=True, bw_adjust=1.2)\n",
    "\n",
    "plt.title('Response Collection Length Distribution')\n",
    "plt.xlabel('Response Length')\n",
    "plt.ylabel('Density')\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autogpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
